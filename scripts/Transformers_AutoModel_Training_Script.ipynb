{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transformers - AutoModel Training Script",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMTBHEtMYScK",
        "outputId": "7a4bc5b1-8e00-4eb1-f2dd-10bf841cb0c3"
      },
      "source": [
        "!pip install transformers datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.15.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.11.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.7)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (5.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBijoECffCGT",
        "outputId": "8aefd751-daab-45f3-a307-b942b67c46fd"
      },
      "source": [
        "% cd '/content/drive/MyDrive/Final Year Project/'\n",
        "% ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Final Year Project\n",
            " \u001b[0m\u001b[01;34mdata\u001b[0m/   \u001b[01;34mmodels\u001b[0m/                Resources.gdoc   vectorizer.joblib\n",
            " \u001b[01;34mlogs\u001b[0m/  'Proposal Draft.gdoc'   \u001b[01;34mscripts\u001b[0m/         wrongly_classified_images.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D4CBblE_e1cC",
        "outputId": "320fd4ef-dea3-432c-c9fc-7c1064183c6a"
      },
      "source": [
        "# Load Data\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "data = pd.read_csv('data/memotion_dataset_7k/labels.csv')\n",
        "data.image_name = data.image_name.str.lower()\n",
        "data = data.set_index('image_name', drop=False)\n",
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_name</th>\n",
              "      <th>text_ocr</th>\n",
              "      <th>text_corrected</th>\n",
              "      <th>humour</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>offensive</th>\n",
              "      <th>motivational</th>\n",
              "      <th>overall_sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_1.jpg</th>\n",
              "      <td>0</td>\n",
              "      <td>image_1.jpg</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIKUT TREND PLAY THE 10 YEARS CHALLENGE AT FACEBOOK imgflip.com</td>\n",
              "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIKUT TREND PLAY THE 10 YEARS CHALLENGE AT FACEBOOK imgflip.com</td>\n",
              "      <td>hilarious</td>\n",
              "      <td>general</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>very_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_2.jpeg</th>\n",
              "      <td>1</td>\n",
              "      <td>image_2.jpeg</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in less the 4 years. Kudus to @narendramodi ji 8:05 PM - 16 Jan 2019 from Mumbai</td>\n",
              "      <td>The best of #10 YearChallenge! Completed in less the 4 years. Kudus to @narendramodi ji 8:05 PM - 16 Jan 2019 from Mumbai  India</td>\n",
              "      <td>not_funny</td>\n",
              "      <td>general</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>motivational</td>\n",
              "      <td>very_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_3.jpg</th>\n",
              "      <td>2</td>\n",
              "      <td>image_3.jpg</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw everyone posting these 2009 vs 2019 pics so here's mine 6:23 PM - 12 Jan 2019 O 636 Retweets 3</td>\n",
              "      <td>Sam Thorne @Strippin ( Follow Follow Saw everyone posting these 2009 vs 2019 pics so here's mine 6:23 PM - 12 Jan 2019 O 636 Retweets 3 224 LIKES 65 636 3.2K</td>\n",
              "      <td>very_funny</td>\n",
              "      <td>not_sarcastic</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_4.png</th>\n",
              "      <td>3</td>\n",
              "      <td>image_4.png</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
              "      <td>very_funny</td>\n",
              "      <td>twisted_meaning</td>\n",
              "      <td>very_offensive</td>\n",
              "      <td>motivational</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_5.png</th>\n",
              "      <td>4</td>\n",
              "      <td>image_5.png</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious 10 Year Challenge Memes | What is #10 Year Challenge?</td>\n",
              "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious 10 Year Challenge Memes | What is #10 Year Challenge?</td>\n",
              "      <td>hilarious</td>\n",
              "      <td>very_twisted</td>\n",
              "      <td>very_offensive</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_6988.jpg</th>\n",
              "      <td>6987</td>\n",
              "      <td>image_6988.jpg</td>\n",
              "      <td>Tuesday is Mardi Gras Wednesday is Valentine's Friday is the Chinese New Year To those who celebrate in full force; I'll be waiting for you at the end of the week with a digestive blend. ESSENTIALOILSTYLE.COM</td>\n",
              "      <td>Tuesday is Mardi Gras Wednesday is Valentine's Friday is the Chinese New Year To those who celebrate in full force; I'll be waiting for you at the end of the week with a digestive blend. ESSENTIALOILSTYLE.COM</td>\n",
              "      <td>very_funny</td>\n",
              "      <td>twisted_meaning</td>\n",
              "      <td>very_offensive</td>\n",
              "      <td>motivational</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_6989.jpg</th>\n",
              "      <td>6988</td>\n",
              "      <td>image_6989.jpg</td>\n",
              "      <td>MUST WATCH MOVIES OF 2017 ITI Chennai memes MAANAGARAM A HANDFUL OF DIVERSE CHARACTERS FIND THEMSELVES IN EXTRAORDINARY SITUATIONS THAT ARE INTERLINKED WITH ONE ANOTHER</td>\n",
              "      <td>MUST WATCH MOVIES OF 2017 ITI Chennai memes MAANAGARAM A HANDFUL OF DIVERSE CHARACTERS FIND THEMSELVES IN EXTRAORDINARY SITUATIONS THAT ARE INTERLINKED WITH ONE ANOTHER</td>\n",
              "      <td>funny</td>\n",
              "      <td>twisted_meaning</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_6990.png</th>\n",
              "      <td>6989</td>\n",
              "      <td>image_6990.png</td>\n",
              "      <td>LESS MORE TALKING PLANNING SODA JUNK FOOD COMPLAINING WORRYING DOUBTING LAZING AROUND FROWNING INSECURITY WEAKNESS IGNORANCE HATE UNGRATEFULNESS LISTENING DOING TEA SALADS ENCOURAGING HOPING BELIEVING WORKING OUT SMILING TRUST CONFIDENCE UNDERSTANDING LOVE GRATITUDE An easy guide to making the rest of 2017 the best of 2017...</td>\n",
              "      <td>LESS MORE TALKING PLANNING SODA JUNK FOOD COMPLAINING WORRYING DOUBTING LAZING AROUND FROWNING INSECURITY WEAKNESS IGNORANCE HATE UNGRATEFULNESS LISTENING DOING TEA SALADS ENCOURAGING HOPING BELIEVING WORKING OUT SMILING TRUST CONFIDENCE UNDERSTANDING LOVE GRATITUDE An easy guide to making the rest of 2017 the best of 2017...</td>\n",
              "      <td>funny</td>\n",
              "      <td>general</td>\n",
              "      <td>slight</td>\n",
              "      <td>not_motivational</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_6991.jpg</th>\n",
              "      <td>6990</td>\n",
              "      <td>image_6991.jpg</td>\n",
              "      <td>When I VERY have time is a fantasy No one has time unless they make time. ARHtisticLicense.com</td>\n",
              "      <td>When I have time is a fantasy. no one has time unless they make time. ARHtisticLicense.com</td>\n",
              "      <td>not_funny</td>\n",
              "      <td>twisted_meaning</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>motivational</td>\n",
              "      <td>very_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_6992.jpg</th>\n",
              "      <td>6991</td>\n",
              "      <td>image_6992.jpg</td>\n",
              "      <td>The starting point for every good idea is \"What if... ARHtistic License.com</td>\n",
              "      <td>The starting point for every good idea is \"What if... \" ARHtistic License.com</td>\n",
              "      <td>not_funny</td>\n",
              "      <td>not_sarcastic</td>\n",
              "      <td>not_offensive</td>\n",
              "      <td>motivational</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6992 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Unnamed: 0      image_name  ...      motivational overall_sentiment\n",
              "image_name                                  ...                                    \n",
              "image_1.jpg              0     image_1.jpg  ...  not_motivational     very_positive\n",
              "image_2.jpeg             1    image_2.jpeg  ...      motivational     very_positive\n",
              "image_3.jpg              2     image_3.jpg  ...  not_motivational          positive\n",
              "image_4.png              3     image_4.png  ...      motivational          positive\n",
              "image_5.png              4     image_5.png  ...  not_motivational           neutral\n",
              "...                    ...             ...  ...               ...               ...\n",
              "image_6988.jpg        6987  image_6988.jpg  ...      motivational           neutral\n",
              "image_6989.jpg        6988  image_6989.jpg  ...  not_motivational           neutral\n",
              "image_6990.png        6989  image_6990.png  ...  not_motivational          positive\n",
              "image_6991.jpg        6990  image_6991.jpg  ...      motivational     very_positive\n",
              "image_6992.jpg        6991  image_6992.jpg  ...      motivational          positive\n",
              "\n",
              "[6992 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-LTVRsrs_QT"
      },
      "source": [
        "url_regex = '(https?:\\/\\/)?([\\dA-Za-z\\.-]+)\\.([A-Za-z\\.]{2,6})([\\/\\w \\.-]*)'\n",
        "data['text_cleaned'] = data['text_corrected'].str.replace(url_regex, '', regex=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCTba_GVLzKb"
      },
      "source": [
        "anno = pd.read_csv('data/memotion_dataset_7k/annotations/annotations.csv')\n",
        "anno.columns = ['index', 'image', 'labels']\n",
        "del anno['index']\n",
        "anno = anno.drop_duplicates().sort_values('image', ignore_index=True)\n",
        "anno.labels = anno.labels.apply(eval)\n",
        "anno = anno.groupby('image').sum()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqX6ZLvqRlkr"
      },
      "source": [
        "all_labels = set()\n",
        "for labels in anno.labels:\n",
        "    labels = set() if type(labels) != set else labels\n",
        "    all_labels.update(labels)\n",
        "all_labels -= {None}\n",
        "\n",
        "meme = set()\n",
        "for label in all_labels:\n",
        "    if 'meme' in label.lower():\n",
        "        meme.add(label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36gsFZvFRNbB"
      },
      "source": [
        "EXCLUDED_KEYWORDS = meme\n",
        "EXCLUDED_KEYWORDS.update({'Image', 'Imgur', None, 'Humour', 'Text','Stock photography'})"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSisHxvMiwG"
      },
      "source": [
        "data = data.join(anno)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mz1Foh1gPpR"
      },
      "source": [
        "train_texts, train_labels = data.text_cleaned.astype(str).to_list(), data.overall_sentiment.astype(str).to_list()\n",
        "set(train_labels)\n",
        "train_labels = [2 if 'positive' in x else 1 if 'negative' in x else 0 for x in train_labels]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITm7AGkIf1tA"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLbw4K4lh6_t"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOTvl3nofwHw",
        "outputId": "24986a38-1c74-4d47-9221-65f1bfcef2fe"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv02IYaperAB"
      },
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ4Mwmakerm8"
      },
      "source": [
        "class MemotionCaptionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, encodings, labels):\n",
        "        self.texts = texts\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['text'] = self.texts[idx]\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = MemotionCaptionDataset(train_texts, train_encodings, train_labels)\n",
        "val_dataset = MemotionCaptionDataset(val_texts, val_encodings, val_labels)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_nbtkxTGtlr"
      },
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "rXPGYu-yezrE",
        "outputId": "4fdca217-0ae3-450b-b2dd-3df326bde7f3"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='models/roberta-finetuned',          # output directory\n",
        "    num_train_epochs=10,              # total number of training epochs\n",
        "    per_device_train_batch_size=32,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=200,\n",
        "    \n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 5593\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1750\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1750' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1750/1750 19:06, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.940100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.900600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.893600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.894900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.893900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.893100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.896700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.893700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to models/roberta-finetuned/checkpoint-500\n",
            "Configuration saved in models/roberta-finetuned/checkpoint-500/config.json\n",
            "Model weights saved in models/roberta-finetuned/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to models/roberta-finetuned/checkpoint-1000\n",
            "Configuration saved in models/roberta-finetuned/checkpoint-1000/config.json\n",
            "Model weights saved in models/roberta-finetuned/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to models/roberta-finetuned/checkpoint-1500\n",
            "Configuration saved in models/roberta-finetuned/checkpoint-1500/config.json\n",
            "Model weights saved in models/roberta-finetuned/checkpoint-1500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1399\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 10.0,\n",
              " 'eval_accuracy': 0.5889921372408864,\n",
              " 'eval_loss': 0.8972378969192505,\n",
              " 'eval_runtime': 4.6306,\n",
              " 'eval_samples_per_second': 302.123,\n",
              " 'eval_steps_per_second': 4.751}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm8IDgXZ6p3L",
        "outputId": "ba0cee4a-601b-429e-d09a-2c010489da18"
      },
      "source": [
        "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=False, device=0)\n",
        "pipeline\n",
        "\n",
        "outputs = [out['label'] for out in pipeline(val_texts)]\n",
        "pd.Series(outputs).value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LABEL_2    1399\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x8g5DpubKCE"
      },
      "source": [
        "id2label = {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHb5uROrIw-w",
        "outputId": "263fe5fc-df17-4f43-dab5-6d331c7cd9b6"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = val_labels\n",
        "y_pred = [id2label[out] for out in outputs]\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24711351027140502"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xnsIGQGThnC"
      },
      "source": [
        "def check_accuracy(model_name, y_true, y_pred):\n",
        "    print(\"Accuracy of \" + model_name + \": {}%\".format(round(accuracy_score(y_true, y_pred)*100,2)))\n",
        "    print(\"\\nConfusion Matrix of \" + model_name + \":\\n\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(\"\\nClassification Report of \" + model_name + \":\\n\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(\"F1 Macro Score: \" + str(f1_score(y_true, y_pred, average='macro')))\n",
        "\n",
        "#row True col predicted"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-QktBeWROUF"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}